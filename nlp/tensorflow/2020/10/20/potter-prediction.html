<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Predicting text for a Harry Potter book | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Predicting text for a Harry Potter book" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We will try to predict text in context to a Harry Potter novel." />
<meta property="og:description" content="We will try to predict text in context to a Harry Potter novel." />
<link rel="canonical" href="https://shirolepranav.github.io/blog/nlp/tensorflow/2020/10/20/potter-prediction.html" />
<meta property="og:url" content="https://shirolepranav.github.io/blog/nlp/tensorflow/2020/10/20/potter-prediction.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-20T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Predicting text for a Harry Potter book" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2020-10-20T00:00:00-05:00","datePublished":"2020-10-20T00:00:00-05:00","description":"We will try to predict text in context to a Harry Potter novel.","headline":"Predicting text for a Harry Potter book","mainEntityOfPage":{"@type":"WebPage","@id":"https://shirolepranav.github.io/blog/nlp/tensorflow/2020/10/20/potter-prediction.html"},"url":"https://shirolepranav.github.io/blog/nlp/tensorflow/2020/10/20/potter-prediction.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://shirolepranav.github.io/blog/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Predicting text for a Harry Potter book</h1><p class="page-description">We will try to predict text in context to a Harry Potter novel.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-10-20T00:00:00-05:00" itemprop="datePublished">
        Oct 20, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      12 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#nlp">nlp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#tensorflow">tensorflow</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/shirolepranav/blog/tree/master/_notebooks/2020-10-20-potter-prediction.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/shirolepranav/blog/master?filepath=_notebooks%2F2020-10-20-potter-prediction.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/shirolepranav/blog/blob/master/_notebooks/2020-10-20-potter-prediction.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          <div class="px-2">
  <a href="https://deepnote.com/launch?url=https%3A%2F%2Fgithub.com%2Fshirolepranav%2Fblog%2Fblob%2Fmaster%2F_notebooks%2F2020-10-20-potter-prediction.ipynb" target="_blank">
      <img class="notebook-badge-image" src="/blog/assets/badges/deepnote.svg" alt="Launch in Deepnote"/>
  </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-10-20-potter-prediction.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this blog post, we will try to predict text in context to a Harry Potter novel.</p>
<p>In text prediction, we can get a body of texts, extract the vocabulary from it, and then create datasets from that, where we make it phrase the Xs, and the next word in that phrase will be the Ys.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Bidirectional</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">regularizers</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.utils</span> <span class="k">as</span> <span class="nn">ku</span> 
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our sample text is from the Harry Potter books. We'll create a Python list of sentences from the data and convert all of that to lowercase.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Using the <code>tokenizer</code>, we'll call <code>fit_on_texts</code> to this corpus of work and it will create the dictionary of words and the overall corpus. This is a key-value pair, with the key being the word, and the value being the token for that word.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'/content/potter.txt'</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpus</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">corpus</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>["mr. and mrs. dursley, of number four, privet drive, were proud to say that they were perfectly normal, thank you very much. they were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. ",
 'mr. dursley was the director of a firm called grunnings, which made drills. he was a big, beefy man with hardly any neck, although he did have a very large mustache. mrs. dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. the dursleys had a small son called dudley and in their opinion there was no finer boy anywhere. ',
 "the dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. they didn't think they could bear it if anyone found out about the potters. mrs. potter was mrs. dursley's sister, but they hadn't met for several years; in fact, mrs. dursley pretended she didn't have a sister, because her sister and her good-for-nothing husband were as undursleyish as it was possible to be. the dursleys shuddered to think what the neighbors would say if the potters arrived in the street. the dursleys knew that the potters had a small son, too, but they had never even seen him. this boy was another good reason for keeping the potters away; they didn't want dudley mixing with a child like that. ",
 'when mr. and mrs. dursley woke up on the dull, gray tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. mr. dursley hummed as he picked out his most boring tie for work, and mrs. dursley gossiped away happily as she wrestled a screaming dudley into his high chair. ',
 'none of them noticed a large, tawny owl flutter past the window. ',
 'at half past eight, mr. dursley picked up his briefcase, pecked mrs. dursley on the cheek, and tried to kiss dudley good-bye but missed, because dudley was now having a tantrum and throwing his cereal at the walls. "little tyke," chortled mr. dursley as he left the house. he got into his car and backed out of number four\'s drive. ',
 "it was on the corner of the street that he noticed the first sign of something peculiar -- a cat reading a map. for a second, mr. dursley didn't realize what he had seen -- then he jerked his head around to look again. there was a tabby cat standing on the corner of privet drive, but there wasn't a map in sight. what could he have been thinking of? it must have been a trick of the light. mr. dursley blinked and stared at the cat. it stared back. as mr. dursley drove around the corner and up the road, he watched the cat in his mirror. it was now reading the sign that said privet drive -- no, looking at the sign; cats couldn't read maps or signs. mr. dursley gave himself a little shake and put the cat out of his mind. as he drove toward town he thought of nothing except a large order of drills he was hoping to get that day. ",
 "but on the edge of town, drills were driven out of his mind by something else. as he sat in the usual morning traffic jam, he couldn't help noticing that there seemed to be a lot of strangely dressed people about. people in cloaks. mr. dursley couldn't bear people who dressed in funny clothes -- the getups you saw on young people! he supposed this was some stupid new fashion. he drummed his fingers on the steering wheel and his eyes fell on a huddle of these weirdos standing quite close by. they were whispering excitedly together. mr. dursley was enraged to see that a couple of them weren't young at all; why, that man had to be older than he was, and wearing an emerald-green cloak! the nerve of him! but then it struck mr. dursley that this was probably some silly stunt -- these people were obviously collecting for something... ",
 'yes, that would be it. the traffic moved on and a few minutes later, mr. dursley arrived in the grunnings parking lot, his mind back on drills. ',
 "mr. dursley always sat with his back to the window in his office on the ninth floor. if he hadn't, he might have found it harder to concentrate on drills that morning. he didn't see the owls swoop ing past in broad daylight, though people down in the street did; they pointed and gazed open- mouthed as owl after owl sped overhead. most of them had never seen an owl even at nighttime. mr. dursley, however, had a perfectly normal, owl-free morning. he yelled at five different people. he made several important telephone calls and shouted a bit more. he was in a very good mood until lunchtime, when he thought he'd stretch his legs and walk across the road to buy himself a bun from the bakery. "]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We then find the total number of words in the corpus by getting the length of its <code>word_index</code>. We add <code>1</code> to this to consider out-of-vocabulary variables.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">()</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">total_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's take this corpus and turn it into training data.<br>
Our training Xs will be a Python list called <code>input_sequences</code>. Then for each line in the corpus, we'll generate a token list using the tokenizer's <code>texts_to_sequences</code> method. This will convert a line of text into a list of the tokens representing the words.<br>
Then we'll iterate over this list of tokens and create a number of <code>n_gram_sequence</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">input_sequences</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">corpus</span><span class="p">:</span>
	<span class="n">token_list</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">line</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_list</span><span class="p">)):</span>
		<span class="n">n_gram_sequence</span> <span class="o">=</span> <span class="n">token_list</span><span class="p">[:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
		<span class="n">input_sequences</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_gram_sequence</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we need to find the length of the longest sentence in the corpus. Then we pad all of the sequences so that they are of the same length. We'll use <code>padding = pre</code> so as to make it easier to extract the label.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">max_sequence_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_sequences</span><span class="p">])</span>
<span class="n">input_sequences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">input_sequences</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_sequence_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'pre'</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we turn the sequences into our Xs (input values) and Ys (labels). All we do is take all except the last character as our X, and the last character as our Y.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">predictors</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">input_sequences</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">input_sequences</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we'll one-hot-encode our labels as this is really a classification problem, where given a sequence of qords, we can classify from the corpus what the next word would likely be. We use the keras utility function to convert a list into a categorical</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">label</span> <span class="o">=</span> <span class="n">ku</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">total_words</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we'll create a neural network to train it with the data. It's a <code>Sequential</code> model with an <code>Embedding</code> with 128 dimensions to handle al of our words. Another parameter i.e. the <code>input_length</code> is equal to the length of the longest sentence minus 1 since we cropped off the last word of each sequence to get the label. It also has an <code>Bidirectional</code> <code>LSTM</code> with 150 units. The cell state of the LSTM will carry context along with them. The model also consists of a <code>Dropout</code> and a couple of <code>Dense</code> layers. The output layer is activated by <code>softmax</code>. Since we're doing a categorical classification, we'll set the loss to be <code>categorical_crossentropy</code>. We'll use the <code>adam</code> optimizer.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">total_words</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">max_sequence_len</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="n">return_sequences</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">total_words</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">total_words</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">total_words</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 201, 128)          772224    
_________________________________________________________________
bidirectional_1 (Bidirection (None, 201, 300)          334800    
_________________________________________________________________
dropout_1 (Dropout)          (None, 201, 300)          0         
_________________________________________________________________
lstm_3 (LSTM)                (None, 100)               160400    
_________________________________________________________________
dense_3 (Dense)              (None, 6033)              609333    
_________________________________________________________________
dense_4 (Dense)              (None, 6033)              36403122  
_________________________________________________________________
dense_5 (Dense)              (None, 6033)              36403122  
=================================================================
Total params: 74,683,001
Trainable params: 74,683,001
Non-trainable params: 0
_________________________________________________________________
None
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will create a <code>callback</code> to stop the training when the model accuracy reaches 85%.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">myCallback</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="p">{}):</span>
    <span class="k">if</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'loss'</span><span class="p">)</span><span class="o">&lt;</span><span class="mf">0.15</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Reached 85</span><span class="si">% a</span><span class="s2">ccuracy so cancelling training!"</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">callbacks</span> <span class="o">=</span> <span class="n">myCallback</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callbacks</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.7067 - accuracy: 0.1652
Epoch 2/30
2339/2339 [==============================] - 214s 91ms/step - loss: 4.6510 - accuracy: 0.1694
Epoch 3/30
2339/2339 [==============================] - 214s 91ms/step - loss: 4.6034 - accuracy: 0.1739
Epoch 4/30
2339/2339 [==============================] - 214s 91ms/step - loss: 4.5633 - accuracy: 0.1779
Epoch 5/30
2339/2339 [==============================] - 214s 91ms/step - loss: 4.5193 - accuracy: 0.1829
Epoch 6/30
2339/2339 [==============================] - 214s 91ms/step - loss: 4.4793 - accuracy: 0.1864
Epoch 7/30
2339/2339 [==============================] - 215s 92ms/step - loss: 4.4420 - accuracy: 0.1910
Epoch 8/30
2339/2339 [==============================] - 215s 92ms/step - loss: 4.4085 - accuracy: 0.1937
Epoch 9/30
2339/2339 [==============================] - 214s 91ms/step - loss: 4.3689 - accuracy: 0.1977
Epoch 10/30
2339/2339 [==============================] - 214s 91ms/step - loss: 4.3406 - accuracy: 0.2008
Epoch 11/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.3102 - accuracy: 0.2050
Epoch 12/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.2758 - accuracy: 0.2087
Epoch 13/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.2498 - accuracy: 0.2120
Epoch 14/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.2209 - accuracy: 0.2145
Epoch 15/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.1935 - accuracy: 0.2184
Epoch 16/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.1677 - accuracy: 0.2203
Epoch 17/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.1500 - accuracy: 0.2237
Epoch 18/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.1215 - accuracy: 0.2265
Epoch 19/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.0961 - accuracy: 0.2289
Epoch 20/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.0774 - accuracy: 0.2313
Epoch 21/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.0606 - accuracy: 0.2325
Epoch 22/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.0427 - accuracy: 0.2352
Epoch 23/30
2339/2339 [==============================] - 214s 92ms/step - loss: 4.0119 - accuracy: 0.2381
Epoch 24/30
2339/2339 [==============================] - 214s 91ms/step - loss: 3.9982 - accuracy: 0.2412
Epoch 25/30
2339/2339 [==============================] - 214s 91ms/step - loss: 3.9759 - accuracy: 0.2456
Epoch 26/30
2339/2339 [==============================] - 214s 91ms/step - loss: 3.9625 - accuracy: 0.2453
Epoch 27/30
2339/2339 [==============================] - 214s 92ms/step - loss: 3.9490 - accuracy: 0.2473
Epoch 28/30
2339/2339 [==============================] - 213s 91ms/step - loss: 3.9250 - accuracy: 0.2499
Epoch 29/30
2339/2339 [==============================] - 214s 92ms/step - loss: 3.9207 - accuracy: 0.2519
Epoch 30/30
2339/2339 [==============================] - 214s 92ms/step - loss: 3.8909 - accuracy: 0.2519
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'loss'</span><span class="p">]</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training accuracy'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Training Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Training loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now for the fun part! Let's try predicting words using this model that we trained on. We'll seed it with a text and ask the model for the next 6 words.<br>
What the model is doing is that for each of the next 6 words, it's going to create token lists using tokenizer text sequences of the <code>seed_text</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed_text</span> <span class="o">=</span> <span class="s2">"Harry was trying out a new spell when"</span>
<span class="n">next_words</span> <span class="o">=</span> <span class="mi">6</span>
  
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">next_words</span><span class="p">):</span>
	<span class="n">token_list</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">([</span><span class="n">seed_text</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
	<span class="n">token_list</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">([</span><span class="n">token_list</span><span class="p">],</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_sequence_len</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">'pre'</span><span class="p">)</span>
	<span class="n">predicted</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">token_list</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
	<span class="n">output_word</span> <span class="o">=</span> <span class="s2">""</span>
	<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
		<span class="k">if</span> <span class="n">index</span> <span class="o">==</span> <span class="n">predicted</span><span class="p">:</span>
			<span class="n">output_word</span> <span class="o">=</span> <span class="n">word</span>
			<span class="k">break</span>
	<span class="n">seed_text</span> <span class="o">+=</span> <span class="s2">" "</span> <span class="o">+</span> <span class="n">output_word</span>
<span class="nb">print</span><span class="p">(</span><span class="n">seed_text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) &gt; 0.5).astype("int32")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).
  warnings.warn('`model.predict_classes()` is deprecated and '
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Harry was trying out a new spell when he looked into the other room
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>What we see here is that the sentence predicted does make sense gramatically. But because our dataset is comparatively small and each prediction is a probability, the quality of the prediction is bound to get worse further down the line.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="shirolepranav/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/nlp/tensorflow/2020/10/20/potter-prediction.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" target="_blank" title="fastai"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" target="_blank" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
